{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for loading in data set from:\n",
    "# https://pythonbasics.org/how-to-load-machine-learning-data-in-python/\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePlot(accuracies,feature_sets):\n",
    "    # Makes a bar chart of the results\n",
    "    fig, ax = plt.subplots(figsize=(10,4.8))\n",
    "    if len(str(feature_sets[0])) < len(str(feature_sets[1])):\n",
    "        title = 'Forward Feature Search'\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        title = 'Backward Feature Search'\n",
    "        plt.title(title)\n",
    "    \n",
    "    ax.bar(range(len(feature_sets)), accuracies, width=0.4)\n",
    "    if len(feature_sets) < 10:\n",
    "        plt.xticks(range(len(feature_sets)), feature_sets)\n",
    "    elif title == 'Backward Feature Search':\n",
    "        plt.xticks(range(len(feature_sets)), reversed(range(len(feature_sets))))\n",
    "    \n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Feature Set')\n",
    "    fig.autofmt_xdate()\n",
    "    #image_format = 'svg'\n",
    "    #image_name = input('input file name: ')\n",
    "    #fig.savefig(image_name, format=image_format, dpi =1200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeaveOneOutCrossValid(data, current_set, feature_to_add_or_remove, search_method):\n",
    "    # Leave one out cross validation, returns the accuracy\n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    # zero columns\n",
    "    if search_method == \"forward\":\n",
    "        # zero out the columns that do not contain features in the current set and the feature to add\n",
    "        for feature in range(1,cols):\n",
    "            if (feature not in current_set) and (feature != feature_to_add_or_remove):\n",
    "                data[:,feature] = 0\n",
    "    elif search_method == \"backward\":\n",
    "        # zero out the columns that contain the feature to remove and the features that are not in the current set\n",
    "        for feature in range(1, cols):\n",
    "            if (feature not in current_set) or (feature == feature_to_add_or_remove):\n",
    "                data[:,feature] = 0  \n",
    "    else:\n",
    "        return 0\n",
    "    NumCorrect = 0\n",
    "    for i in range(rows):\n",
    "        ObjToClassify = data[i,1:]\n",
    "        LabelObjToClassify = data[i,0]\n",
    "        NearestNeighborDistance = np.inf\n",
    "        NearestNeighborLocation = np.inf\n",
    "        for k in range(rows):\n",
    "            if not k == i: # except self\n",
    "                distance = np.sqrt(np.sum((ObjToClassify - data[k,1:]) ** 2))\n",
    "                if distance < NearestNeighborDistance:\n",
    "                    NearestNeighborDistance = distance\n",
    "                    NearestNeighborLocation = k\n",
    "                    NearestNeighborLabel = data[NearestNeighborLocation,0]\n",
    "        if LabelObjToClassify == NearestNeighborLabel:\n",
    "            NumCorrect = NumCorrect + 1 \n",
    "    \n",
    "    accuracy = NumCorrect / rows\n",
    "    return accuracy\n",
    "\n",
    "def forward_feature_search(data):\n",
    "    CurrentSet = set()\n",
    "    BestAcc = 0\n",
    "    # Deafult rate\n",
    "    Data = copy.deepcopy(data)\n",
    "    default_acc = LeaveOneOutCrossValid(Data, CurrentSet, None, \"forward\")\n",
    "    accuracies = [default_acc]\n",
    "    feature_sets = ['{}']\n",
    "\n",
    "    for i in range(1, data.shape[1]):\n",
    "        FeatureToAddAtThisLevel = set()\n",
    "        BestSoFarAccuracy = 0\n",
    "        \n",
    "        for k in range(1, data.shape[1]):\n",
    "            if not CurrentSet.intersection(set({k})):\n",
    "                Data = copy.deepcopy(data)\n",
    "                accuracy = LeaveOneOutCrossValid(Data, CurrentSet, k, \"forward\")\n",
    "                if accuracy > BestSoFarAccuracy:\n",
    "                    BestSoFarAccuracy = accuracy\n",
    "                    FeatureToAddAtThisLevel = k\n",
    "                    BestAcc = accuracy\n",
    "        CurrentSet.add(FeatureToAddAtThisLevel) \n",
    "        print(f\"On level {i} i added feature {FeatureToAddAtThisLevel} to current set\")\n",
    "        print(f\"Current Set: {CurrentSet}\")\n",
    "        print(f\"Accuracy: {BestAcc}\")\n",
    "        accuracies.append(BestAcc)\n",
    "        feature_sets.append(CurrentSet.copy()) \n",
    "    MakePlot(accuracies, feature_sets)\n",
    "\n",
    "def backward_feature_search(data):\n",
    "    features = [x for x in range(1, data.shape[1])] \n",
    "    CurrentSet = set(features)\n",
    "    BestAcc = 0\n",
    "    # Deafult rate\n",
    "    Data = copy.deepcopy(data)\n",
    "    default_acc = LeaveOneOutCrossValid(Data, CurrentSet, None, \"backward\")\n",
    "    accuracies = [default_acc]\n",
    "    feature_sets = [str(CurrentSet.copy())]\n",
    "\n",
    "    for i in range(1, data.shape[1]):\n",
    "        # The logic should be, feature to remove at this level        \n",
    "        FeatureToRemoveAtThisLevel = set()\n",
    "        BestSoFarAccuracy = 0\n",
    "        for k in range(1, data.shape[1]):\n",
    "            if k in CurrentSet:\n",
    "                # to create columns of zeros without affecting the original array\n",
    "                Data = copy.deepcopy(data)\n",
    "                accuracy = LeaveOneOutCrossValid(Data, CurrentSet, k, \"backward\")\n",
    "                if accuracy > BestSoFarAccuracy:\n",
    "                    BestSoFarAccuracy = accuracy\n",
    "                    FeatureToRemoveAtThisLevel = k\n",
    "                    BestAcc = accuracy\n",
    "        CurrentSet.remove(FeatureToRemoveAtThisLevel) \n",
    "        print(f\"On level {i} i removed feature {FeatureToRemoveAtThisLevel} from current set\")\n",
    "        print(f\"Current Set: {CurrentSet}\")\n",
    "        print(f\"Accuracy: {BestAcc}\")\n",
    "        accuracies.append(BestAcc)\n",
    "        if len(CurrentSet) != 0:\n",
    "            feature_sets.append(CurrentSet.copy())\n",
    "        else:\n",
    "            feature_sets.append('{}')\n",
    "    print(len(accuracies),len(feature_sets))\n",
    "\n",
    "    MakePlot(accuracies,feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/CS170_Small_Data__82.txt'\n",
    "Raw_data = open(filename, 'rt')\n",
    "SmallData = np.loadtxt(Raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing forward feature search on small data set\n",
    "forward_feature_search(SmallData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing backward feature search on small data set\n",
    "backward_feature_search(SmallData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/CS170_Large_Data__2.txt'\n",
    "Raw_data = open(filename, 'rt')\n",
    "LargeData = np.loadtxt(Raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing forward feature search on large data set\n",
    "forward_feature_search(LargeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing backward feature search on large data set1\n",
    "backward_feature_search(LargeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample trace problem\n",
    "print(\"Type in the path of the file to test: \")\n",
    "Filename = input(\"Type in the path of the file to test: \")\n",
    "Raw_trace_data = open(Filename, 'rt')\n",
    "TraceData = np.loadtxt(Raw_trace_data)\n",
    "\n",
    "print(\"Type the number of the algorithm you want to run: \\n\\t 1) Forward Selection \\n\\t 2) Backwards elimination\\n\\n\")\n",
    "choice = int(input(\"Type the number of the algorithm you want to run: \\n\\t 1) Forward Selection \\n\\t 2) Backwards elimination\\n\\n\"))\n",
    "\n",
    "print(f\"This dataset has {TraceData.shape[1] - 1} features, with {TraceData.shape[0]} instances.\\n\")\n",
    "\n",
    "if choice == 1:\n",
    "    print(f\"Running nearest neighbor with all {TraceData.shape[1] - 1} features, using leave-one-out evaluation, I get an\")\n",
    "    CurrentSet = set()\n",
    "    Data = copy.deepcopy(TraceData)\n",
    "    default_acc = LeaveOneOutCrossValid(Data, CurrentSet, None, \"forward\")\n",
    "    print(f\"accuracy of: {default_acc}\")\n",
    "    print(\"Beginning search:\\n\")\n",
    "    forward_feature_search(TraceData)\n",
    "elif choice == 2:\n",
    "    backward_feature_search(TraceData)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
